{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Extraction from Retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores.docarray import DocArrayInMemorySearch\n",
    "from langchain_openai.embeddings import OpenAIEmbeddings\n",
    "from langchain.document_loaders.web_base import WebBaseLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "URL = \"https://en.wikipedia.org/wiki/Charles_Biddle\"\n",
    "loader = WebBaseLoader(URL)\n",
    "documents = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(chunk_overlap=0)\n",
    "embeddings = OpenAIEmbeddings()\n",
    "print(len(documents))\n",
    "\n",
    "db = DocArrayInMemorySearch.from_documents(documents=documents, embedding=embeddings)\n",
    "retriever = db.as_retriever()\n",
    "\n",
    "#retriever.get_relevant_documents(\"first name\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "basic_info_function = {\n",
    "    'name': 'Basic_Information',\n",
    "    'description': 'Basic information to extract about the person subject of a text.',\n",
    "    'parameters': {\n",
    "        'title': 'Basic Information',\n",
    "        'description': 'Basic information to extract about the person subject of a text.',\n",
    "        'type': 'object',\n",
    "        'properties': {\n",
    "            'basic_info': {\n",
    "                'title': 'Basic Info',\n",
    "                'description': 'Basic info about the person subject.',\n",
    "                'type': 'object',\n",
    "                'properties': {\n",
    "                    'first_name': {\n",
    "                        'title': 'First Name',\n",
    "                        'description': 'persons first name',\n",
    "                        'type': 'string'\n",
    "                    },\n",
    "                    'last_name': {\n",
    "                        'title': 'Last Name',\n",
    "                        'description': 'persons last name',\n",
    "                        'type': 'string'\n",
    "                    },\n",
    "                    'birth_year': {\n",
    "                        'title': 'Birth Year',\n",
    "                        'description': 'persons birth year',\n",
    "                        'type': 'string'\n",
    "                    },\n",
    "                    'death_year': {\n",
    "                        'title': 'Death Year',\n",
    "                        'description': 'persons death year',\n",
    "                        'type': 'string'\n",
    "                    }\n",
    "                },\n",
    "                'required': ['first_name', 'last_name']\n",
    "            },\n",
    "        },\n",
    "        'required': ['basic_info']\n",
    "    }\n",
    "}\n",
    "\n",
    "extraction_functions = [basic_info_function]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.output_parsers.openai_functions import JsonKeyOutputFunctionsParser, JsonOutputFunctionsParser\n",
    "from langchain_core.prompts.chat import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnableMap\n",
    "from langchain_openai.chat_models import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"A article will be passed to you. Extract from it the basic information from the article about the person who is the subject. \n",
    "\n",
    "Do not make up or guess ANY extra information. Only extract what exactly is in the text.\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", template),\n",
    "    (\"human\", \"{input}\")\n",
    "])\n",
    "\n",
    "\n",
    "basic_info_model = ChatOpenAI(temperature=0.0).bind(functions=extraction_functions)\n",
    "\n",
    "\n",
    "extraction_chain = (\n",
    "    RunnableMap({\n",
    "        \"input\": lambda x: retriever.get_relevant_documents(query=x[\"question\"])\n",
    "    }) \n",
    "    | prompt \n",
    "    | basic_info_model \n",
    "    | JsonOutputFunctionsParser()\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'basic_info': {'first_name': 'Charles',\n",
       "  'last_name': 'Biddle',\n",
       "  'birth_year': '1745',\n",
       "  'death_year': '1821'}}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extraction_chain.invoke({\"question\": \"Charles Biddle\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's Pass a URL and Schema..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import CharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wikipedia Person Pages\n",
    "PREVOST_URL = \"https://en.wikipedia.org/wiki/Jacques_Marcus_Prevost\"\n",
    "BOUQUET_URL = \"https://en.wikipedia.org/wiki/Henry_Bouquet\"\n",
    "DICKINSON_URL = \"https://en.wikipedia.org/wiki/John_Dickinson\"\n",
    "\n",
    "# Variable schema to be passed to extraction chain \n",
    "BASIC_INFO_SCHEMA = {\n",
    "    'properties': {\n",
    "        'first_name': {\n",
    "            'title': 'First Name',\n",
    "            'description': 'persons first name',\n",
    "            'type': 'string'\n",
    "        },\n",
    "        'last_name': {\n",
    "            'title': 'Last Name',\n",
    "            'description': 'persons last name',\n",
    "            'type': 'string'\n",
    "        },\n",
    "        'birth_year': {\n",
    "            'title': 'Birth Year',\n",
    "            'description': 'persons birth year',\n",
    "            'type': 'string'\n",
    "        },\n",
    "        'death_year': {\n",
    "            'title': 'Death Year',\n",
    "            'description': 'persons death year',\n",
    "            'type': 'string'\n",
    "        }\n",
    "    },\n",
    "    'required': ['first_name', 'last_name']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = OpenAIEmbeddings()\n",
    "\n",
    "def get_embeddings_for_query(x):\n",
    "    WIKI_URL = x['url']\n",
    "    schema = x['schema']\n",
    "\n",
    "    splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=10)\n",
    "    raw_docs = WebBaseLoader(WIKI_URL).load()\n",
    "    split_docs = splitter.split_documents(raw_docs)\n",
    "\n",
    "    db = DocArrayInMemorySearch.from_documents(documents=split_docs, embedding=embeddings).as_retriever() # Do I need this abstraction..\n",
    "\n",
    "    # docs = {} Was going to use dict for tracking duplicates... \n",
    "    rel_doc_list = []\n",
    "    for i, key in enumerate(schema['properties'].keys()):\n",
    "        docs = db.get_relevant_documents(query=key)\n",
    "        #print(f\"\\nKey: {key}\\nDoc:{docs[0]}\")\n",
    "        rel_doc_list.append(docs[0].page_content)\n",
    "    return {\"input\": rel_doc_list}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created a chunk of size 1509, which is longer than the specified 1000\n",
      "Created a chunk of size 1265, which is longer than the specified 1000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': ['This page was last edited on 9 March 2023, at 10:55\\xa0(UTC).\\nText is available under the Creative Commons Attribution-ShareAlike License 4.0;\\nadditional terms may apply.  By using this site, you agree to the Terms of Use and Privacy Policy. Wikipedia® is a registered trademark of the Wikimedia Foundation, Inc., a non-profit organization.\\n\\n\\nPrivacy policy\\nAbout Wikipedia\\nDisclaimers\\nContact Wikipedia\\nCode of Conduct\\nDevelopers\\nStatistics\\nCookie statement\\nMobile view\\n\\nToggle limited content width',\n",
       "  \"Marriage and family[edit]\\nWhile in New York City convalescing, Jacques Marc had met Theodosia Stillwell Bartow. They married in Trinity Church in 1763. They had five children together, including Augustine James Frederick Prevost (1765–1842) and John Bartow Prevost (1766–1825).\\nWhile Jacques was away fighting for the British in the West Indies, his wife Theodosia formed a relationship with an American colonel named Aaron Burr, who was ten years younger than her. In 1781, soon after learning of her husband's death, the newly widowed Theodosia got remarried to the young Burr, who adopted the Prevost family's five children. Burr and Theodosia had another five children together, but only their daughter Theodosia Burr Alston survived to adulthood, and was later lost at sea.\",\n",
       "  'Download as PDFPrintable version\\n\\nFrom Wikipedia, the free encyclopedia\\n\\n\\nBritish Army officer (1736–1781)',\n",
       "  'Download as PDFPrintable version\\n\\nFrom Wikipedia, the free encyclopedia\\n\\n\\nBritish Army officer (1736–1781)']}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_embeddings_for_query({\"url\": PREVOST_URL, \"schema\": {\"properties\": {\"first_name\": \"\", \"last_name\": \"\", \"year_of_birth\":\"\", \"year of death\": \"\"}}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_extraction_function(entity_schema: dict) -> dict:\n",
    "    return {\n",
    "        \"name\": \"basic_info\",\n",
    "        \"description\": \"Basic information to extract about the person subject of a text.\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"info\": {\"type\": \"array\", \"items\": _convert_schema(entity_schema)}\n",
    "            },\n",
    "            \"required\": [\"info\"],\n",
    "        },\n",
    "    }\n",
    "\n",
    "def _convert_schema(schema: dict) -> dict:\n",
    "    props = {k: {\"title\": k, **v} for k, v in schema[\"properties\"].items()}\n",
    "    return {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": props,\n",
    "        \"required\": schema.get(\"required\", []),\n",
    "    }\n",
    "\n",
    "def get_llm_kwargs(function: dict) -> dict:\n",
    "    \"\"\"Returns the kwargs for the LLMChain constructor.\n",
    "\n",
    "    Args:\n",
    "        function: The function to use.\n",
    "\n",
    "    Returns:\n",
    "        The kwargs for the LLMChain constructor.\n",
    "    \"\"\"\n",
    "    return {\"functions\": [function], \"function_call\": {\"name\": function[\"name\"]}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def invoke_model_with_schema(x):\n",
    "    model = ChatOpenAI(temperature=0.0)\n",
    "    schema = x[\"schema\"]\n",
    "    function_def = get_extraction_function(schema)\n",
    "    res = model.invoke(x['input'].messages, **get_llm_kwargs(function_def))\n",
    "    \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best way I know how for now... - rough draft\n",
    "\n",
    "from operator import itemgetter\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "\n",
    "person_extraction_chain = (\n",
    "    {\n",
    "        \"input\": get_embeddings_for_query | prompt,\n",
    "        \"schema\": itemgetter(\"schema\")\n",
    "    }\n",
    "    | RunnableLambda(invoke_model_with_schema) \n",
    "    | JsonOutputFunctionsParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created a chunk of size 1509, which is longer than the specified 1000\n",
      "Created a chunk of size 1265, which is longer than the specified 1000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'info': [{'first_name': 'Jacques',\n",
       "   'last_name': 'Prevost',\n",
       "   'birth_year': '1736',\n",
       "   'death_year': ''}]}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "person_extraction_chain.invoke({\"url\": PREVOST_URL, \"schema\": BASIC_INFO_SCHEMA})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created a chunk of size 3149, which is longer than the specified 1000\n",
      "Created a chunk of size 3049, which is longer than the specified 1000\n",
      "Created a chunk of size 4015, which is longer than the specified 1000\n",
      "Created a chunk of size 2917, which is longer than the specified 1000\n",
      "Created a chunk of size 1607, which is longer than the specified 1000\n",
      "Created a chunk of size 2538, which is longer than the specified 1000\n",
      "Created a chunk of size 2927, which is longer than the specified 1000\n",
      "Created a chunk of size 2358, which is longer than the specified 1000\n",
      "Created a chunk of size 1984, which is longer than the specified 1000\n",
      "Created a chunk of size 4204, which is longer than the specified 1000\n",
      "Created a chunk of size 2346, which is longer than the specified 1000\n",
      "Created a chunk of size 1441, which is longer than the specified 1000\n",
      "Created a chunk of size 7517, which is longer than the specified 1000\n",
      "Created a chunk of size 2004, which is longer than the specified 1000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'info': [{'first_name': 'John',\n",
       "   'last_name': 'Dickinson',\n",
       "   'birth_year': '1732',\n",
       "   'death_year': '1808'}]}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "person_extraction_chain.invoke({\"url\": DICKINSON_URL, \"schema\": BASIC_INFO_SCHEMA})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'person_extraction_chain' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 70\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Create more complex schema\u001b[39;00m\n\u001b[1;32m      3\u001b[0m MORE_COMPLEX_INFO_SCHEMA \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mproperties\u001b[39m\u001b[38;5;124m'\u001b[39m: {\n\u001b[1;32m      5\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfirst_name\u001b[39m\u001b[38;5;124m'\u001b[39m: {\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrequired\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfirst_name\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlast_name\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mviews_on_war\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     68\u001b[0m }\n\u001b[0;32m---> 70\u001b[0m \u001b[43mperson_extraction_chain\u001b[49m\u001b[38;5;241m.\u001b[39minvoke({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124murl\u001b[39m\u001b[38;5;124m\"\u001b[39m: DICKINSON_URL, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mschema\u001b[39m\u001b[38;5;124m\"\u001b[39m: MORE_COMPLEX_INFO_SCHEMA})\n",
      "\u001b[0;31mNameError\u001b[0m: name 'person_extraction_chain' is not defined"
     ]
    }
   ],
   "source": [
    "# Create more complex schema\n",
    "\n",
    "MORE_COMPLEX_INFO_SCHEMA = {\n",
    "    'properties': {\n",
    "        'first_name': {\n",
    "            'title': 'First Name',\n",
    "            'description': 'persons first name',\n",
    "            'type': 'string'\n",
    "        },\n",
    "        'last_name': {\n",
    "            'title': 'Last Name',\n",
    "            'description': 'persons last name',\n",
    "            'type': 'string'\n",
    "        },\n",
    "        'children': {\n",
    "            'title': 'Children',\n",
    "            'description': 'persons children',\n",
    "            'type': 'array',\n",
    "            'items': {\n",
    "                'type': 'object',\n",
    "                'title': 'Child',\n",
    "                'description': 'Child of person',\n",
    "                'properties': {\n",
    "                    'first_name': {\n",
    "                        'title': 'First Name',\n",
    "                        'description': 'childs first name',\n",
    "                        'type': 'string'\n",
    "                    },\n",
    "                    'last_name': {\n",
    "                        'title': 'Last Name',\n",
    "                        'description': 'childs last name',\n",
    "                        'type': 'string'\n",
    "                    }\n",
    "                },\n",
    "                'required': ['first_name', 'last_name']\n",
    "            }\n",
    "        },\n",
    "        'cause_of_death': {\n",
    "            'title': 'Cause of Death',\n",
    "            'description': 'persons cause of death',\n",
    "            'type': 'string'\n",
    "        },\n",
    "        'views_on_war': {\n",
    "            'title': 'Views on War',\n",
    "            'description': 'persons views on war',\n",
    "            'type': 'object',\n",
    "            'items': {\n",
    "                'type': 'object',\n",
    "                'title': 'View on War',\n",
    "                'description': 'View on War',\n",
    "                'properties': {\n",
    "                    'war': {\n",
    "                        'title': 'War',\n",
    "                        'description': 'war',\n",
    "                        'type': 'string'\n",
    "                    },\n",
    "                    'view': {\n",
    "                        'title': 'View',\n",
    "                        'description': 'view on war',\n",
    "                        'type': 'string'\n",
    "                    }\n",
    "                },\n",
    "                'required': ['war', 'view']\n",
    "            }\n",
    "        },\n",
    "    },\n",
    "    'required': ['first_name', 'last_name', 'views_on_war']\n",
    "}\n",
    "\n",
    "person_extraction_chain.invoke({\"url\": DICKINSON_URL, \"schema\": MORE_COMPLEX_INFO_SCHEMA})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementation is a start. Next is developing better retrieval strategies, testing models, sequential calls for the schema, token tracking, prompt engineering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created a chunk of size 3149, which is longer than the specified 1000\n",
      "Created a chunk of size 3049, which is longer than the specified 1000\n",
      "Created a chunk of size 4015, which is longer than the specified 1000\n",
      "Created a chunk of size 2917, which is longer than the specified 1000\n",
      "Created a chunk of size 1607, which is longer than the specified 1000\n",
      "Created a chunk of size 2538, which is longer than the specified 1000\n",
      "Created a chunk of size 2927, which is longer than the specified 1000\n",
      "Created a chunk of size 2358, which is longer than the specified 1000\n",
      "Created a chunk of size 1984, which is longer than the specified 1000\n",
      "Created a chunk of size 4204, which is longer than the specified 1000\n",
      "Created a chunk of size 2346, which is longer than the specified 1000\n",
      "Created a chunk of size 1441, which is longer than the specified 1000\n",
      "Created a chunk of size 7517, which is longer than the specified 1000\n",
      "Created a chunk of size 2004, which is longer than the specified 1000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'info': [{'source': 'Ehrlich, Eugene and Gorton Carruth. The Oxford Illustrated Literary Guide to the United States. New York: Oxford University Press, 1982. p. 217. ISBN 0-19-503186-5'},\n",
       "  {'source': \"Lincoln's Little War by Webb B. Garrison, pg. 60\"},\n",
       "  {'source': 'The Thirteen Colonies: Travel Historic America pg. 62'},\n",
       "  {'source': '\"Student finds letter \\'a link to Jefferson\\'\". CNN.com. December 8, 2009. Retrieved May 6, 2010.'},\n",
       "  {'source': '\"Odd Wisconsin Archives\". Wisconsinhistory.org. March 29, 2006. Archived from the original on April 23, 2006. Retrieved September 12, 2012.'},\n",
       "  {'source': 'Rabinowitz, Chloe. \"EXCEPT MR. DICKINSON World Premiere to be Presented by 15th Street Friends\". BroadwayWorld.com.'},\n",
       "  {'source': 'Colbourn, Trevor H. (1959). \"John Dickinson, Historical Revolutionary\". The Pennsylvania Magazine of History and Biography. 83 (3): 271–292. JSTOR 20089207.'},\n",
       "  {'source': 'Powell, John H. \"John Dickinson and the Constitution.\" The Pennsylvania Magazine of History and Biography 60, no. 1 (1936): 5.'}]}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SIMPLE_COMPLEX_INFO_SCHEMA = {\n",
    "    'properties': {\n",
    "        'views_on_war': {\n",
    "            'title': 'Views on War',\n",
    "            'description': 'persons views on war',\n",
    "            'type': 'object',\n",
    "            'items': {\n",
    "                'type': 'object',\n",
    "                'title': 'View on War',\n",
    "                'description': 'View on War',\n",
    "                'properties': {\n",
    "                    'war': {\n",
    "                        'title': 'War',\n",
    "                        'description': 'war',\n",
    "                        'type': 'string'\n",
    "                    },\n",
    "                    'view': {\n",
    "                        'title': 'View',\n",
    "                        'description': 'view on war',\n",
    "                        'type': 'string'\n",
    "                    }\n",
    "                },\n",
    "                'required': ['war', 'view']\n",
    "            }\n",
    "        },\n",
    "    },\n",
    "    'required': ['views_on_war']\n",
    "}\n",
    "\n",
    "person_extraction_chain.invoke({\"url\": DICKINSON_URL, \"schema\": SIMPLE_COMPLEX_INFO_SCHEMA})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementing a HTML Splitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Dict\n",
    "import os\n",
    "import requests\n",
    "from bs4 import BeautifulSoup, Tag, ResultSet\n",
    "from markdownify import MarkdownConverter\n",
    "import chromadb\n",
    "import chromadb.utils.embedding_functions as embedding_functions\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from operator import itemgetter\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "from langchain_core.prompts.chat import ChatPromptTemplate\n",
    "from langchain.output_parsers.openai_functions import JsonKeyOutputFunctionsParser, JsonOutputFunctionsParser\n",
    "from langchain_openai.chat_models import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaner methods\n",
    "from bs4 import ResultSet, Tag\n",
    "def remove_links_from_p(tag:Tag) -> None:\n",
    "    for link in tag.find_all('a'):\n",
    "        link.replace_with(link.text)\n",
    "\n",
    "def remove_citations_from_p(tag:Tag) -> None:\n",
    "    for citation in tag.find_all(class_=\"reference\"):\n",
    "        citation.decompose()\n",
    "\n",
    "def md(soup:str, **options):\n",
    "    return MarkdownConverter(**options).convert_soup(soup)\n",
    "\n",
    "def format_paragraph(element):\n",
    "    remove_links_from_p(element)\n",
    "    remove_citations_from_p(element)\n",
    "    return md(element)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_html_from_wiki_url(url:str) -> Tag:\n",
    "    res = requests.get(url, headers={})\n",
    "    if res.status_code == 200:\n",
    "        soup=BeautifulSoup(res.content,'html.parser')\n",
    "        return soup\n",
    "    else:\n",
    "        raise Exception(f\"Error loading page: {res.status_code}\")\n",
    "    \n",
    "def group_paragraphs_by_section(soup:Tag) -> Dict[str, List[Tag]]:\n",
    "    current_subtitle = \"Overview\"\n",
    "    grouped_content = {}\n",
    "    elements = soup.find_all(['h2', 'h3', 'p'])\n",
    "\n",
    "    for element in elements:\n",
    "        if element.name in ['h2', 'h3']:\n",
    "            current_subtitle = element.get_text(strip=True)\n",
    "            grouped_content[current_subtitle] = []\n",
    "        elif element.name == 'p':\n",
    "            grouped_content.setdefault(current_subtitle, []).append(element)\n",
    "\n",
    "    for subtitle, paragraphs in grouped_content.items():\n",
    "        grouped_content[subtitle] = [format_paragraph(p) for p in paragraphs]\n",
    "\n",
    "    return grouped_content\n",
    "\n",
    "def load_and_clean_from_wiki_url(url:str):\n",
    "    soup = load_html_from_wiki_url(url)\n",
    "    main = soup.find(id=\"mw-content-text\")\n",
    "    return group_paragraphs_by_section(main)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def split_wiki_pars(paragraph_content, splitter):\n",
    "    docs = []\n",
    "    for subtitle, paragraphs in paragraph_content.items():\n",
    "        if paragraphs is None:\n",
    "            continue\n",
    "        split_paragraphs = splitter.create_documents(\n",
    "            texts=paragraphs,\n",
    "            metadatas=[{\"subtitle\": subtitle, \"type\": \"paragraph\"} for _ in paragraphs]\n",
    "        )\n",
    "        docs.extend(split_paragraphs)\n",
    "    return docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)\n",
    "client = chromadb.Client()\n",
    "\n",
    "openai_ef = embedding_functions.OpenAIEmbeddingFunction(\n",
    "            api_key=os.environ[\"OPENAI_API_KEY\"],\n",
    "            model_name=\"text-embedding-ada-002\"\n",
    ")\n",
    "\n",
    "#collection = client.delete_collection(\"wiki_data_bs4\")\n",
    "collection = client.create_collection(\"wiki_data_bs4\", embedding_function=openai_ef)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_embeddings_for_query_wiki_split(x):\n",
    "    WIKI_URL = x['url']\n",
    "    schema = x['schema']\n",
    "\n",
    "    grouped_paragraphs = load_and_clean_from_wiki_url(WIKI_URL)\n",
    "    docs = split_wiki_pars(grouped_paragraphs, splitter)\n",
    "    \n",
    "    collection.add(\n",
    "        documents=[doc.page_content for doc in docs],\n",
    "        ids=[str(i) for i in range(len(docs))],\n",
    "        metadatas=[doc.metadata for doc in docs]\n",
    "    )\n",
    "\n",
    "    # docs = {} Was going to use dict for tracking duplicates... \n",
    "    rel_doc_list = []\n",
    "    for i, key in enumerate(schema['properties'].keys()):\n",
    "        sim_docs = collection.query(query_texts=[key], n_results=3)\n",
    "        #print(f\"\\nKey: {key}\\nDoc:{docs[0]}\")\n",
    "        #rel_doc_list.append(docs[0].page_content)\n",
    "        rel_doc_list.extend(sim_docs['documents'])\n",
    "    return {\"input\": rel_doc_list}\n",
    "\n",
    "def invoke_model_with_schema(x):\n",
    "    model = ChatOpenAI(temperature=0.0)\n",
    "    schema = x[\"schema\"]\n",
    "    function_def = get_extraction_function(schema)\n",
    "    return model.invoke(x['input'].messages, **get_llm_kwargs(function_def))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"A article will be passed to you. Extract from it the basic information from the article about the person who is the subject. \n",
    "\n",
    "Do not make up or guess ANY extra information. Only extract what exactly is in the text.\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", template),\n",
    "    (\"human\", \"{input}\")\n",
    "])\n",
    "\n",
    "\n",
    "person_extraction_chain_wiki_split = (\n",
    "    {\n",
    "        \"input\": get_embeddings_for_query_wiki_split | prompt,\n",
    "        \"schema\": itemgetter(\"schema\")\n",
    "    }\n",
    "    | RunnableLambda(invoke_model_with_schema) \n",
    "    | JsonOutputFunctionsParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wikipedia Person Pages\n",
    "PREVOST_URL = \"https://en.wikipedia.org/wiki/Jacques_Marcus_Prevost\"\n",
    "BOUQUET_URL = \"https://en.wikipedia.org/wiki/Henry_Bouquet\"\n",
    "DICKINSON_URL = \"https://en.wikipedia.org/wiki/John_Dickinson\"\n",
    "\n",
    "# Variable schema to be passed to extraction chain \n",
    "BASIC_INFO_SCHEMA = {\n",
    "    'properties': {\n",
    "        'first_name': {\n",
    "            'title': 'First Name',\n",
    "            'description': 'persons first name',\n",
    "            'type': 'string'\n",
    "        },\n",
    "        'last_name': {\n",
    "            'title': 'Last Name',\n",
    "            'description': 'persons last name',\n",
    "            'type': 'string'\n",
    "        },\n",
    "        'birth_year': {\n",
    "            'title': 'Birth Year',\n",
    "            'description': 'persons birth year',\n",
    "            'type': 'string'\n",
    "        },\n",
    "        'death_year': {\n",
    "            'title': 'Death Year',\n",
    "            'description': 'persons death year',\n",
    "            'type': 'string'\n",
    "        }\n",
    "    },\n",
    "    'required': ['first_name', 'last_name']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'info': [{'first_name': 'John',\n",
       "   'last_name': 'Dickinson',\n",
       "   'birth_year': 'Unknown',\n",
       "   'death_year': '1808'}]}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To reset the DB...\n",
    "collection = client.delete_collection(\"wiki_data_bs4\")\n",
    "collection = client.create_collection(\"wiki_data_bs4\", embedding_function=openai_ef)\n",
    "\n",
    "DICKINSON_URL = \"https://en.wikipedia.org/wiki/John_Dickinson\"\n",
    "person_extraction_chain_wiki_split.invoke({\"url\": DICKINSON_URL, \"schema\": BASIC_INFO_SCHEMA})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Add of existing embedding ID: 0\n",
      "Add of existing embedding ID: 1\n",
      "Add of existing embedding ID: 2\n",
      "Add of existing embedding ID: 3\n",
      "Add of existing embedding ID: 4\n",
      "Add of existing embedding ID: 5\n",
      "Add of existing embedding ID: 6\n",
      "Add of existing embedding ID: 7\n",
      "Add of existing embedding ID: 8\n",
      "Add of existing embedding ID: 9\n",
      "Add of existing embedding ID: 10\n",
      "Add of existing embedding ID: 11\n",
      "Add of existing embedding ID: 12\n",
      "Add of existing embedding ID: 13\n",
      "Add of existing embedding ID: 14\n",
      "Add of existing embedding ID: 15\n",
      "Add of existing embedding ID: 16\n",
      "Add of existing embedding ID: 17\n",
      "Add of existing embedding ID: 18\n",
      "Add of existing embedding ID: 19\n",
      "Add of existing embedding ID: 20\n",
      "Add of existing embedding ID: 21\n",
      "Add of existing embedding ID: 22\n",
      "Add of existing embedding ID: 23\n",
      "Add of existing embedding ID: 24\n",
      "Add of existing embedding ID: 25\n",
      "Add of existing embedding ID: 26\n",
      "Add of existing embedding ID: 27\n",
      "Add of existing embedding ID: 28\n",
      "Add of existing embedding ID: 29\n",
      "Add of existing embedding ID: 30\n",
      "Add of existing embedding ID: 31\n",
      "Add of existing embedding ID: 32\n",
      "Add of existing embedding ID: 33\n",
      "Add of existing embedding ID: 34\n",
      "Add of existing embedding ID: 35\n",
      "Add of existing embedding ID: 36\n",
      "Add of existing embedding ID: 37\n",
      "Add of existing embedding ID: 38\n",
      "Add of existing embedding ID: 39\n",
      "Add of existing embedding ID: 40\n",
      "Add of existing embedding ID: 41\n",
      "Add of existing embedding ID: 42\n",
      "Add of existing embedding ID: 43\n",
      "Add of existing embedding ID: 44\n",
      "Add of existing embedding ID: 45\n",
      "Add of existing embedding ID: 46\n",
      "Add of existing embedding ID: 47\n",
      "Insert of existing embedding ID: 0\n",
      "Insert of existing embedding ID: 1\n",
      "Insert of existing embedding ID: 2\n",
      "Insert of existing embedding ID: 3\n",
      "Insert of existing embedding ID: 4\n",
      "Insert of existing embedding ID: 5\n",
      "Insert of existing embedding ID: 6\n",
      "Insert of existing embedding ID: 7\n",
      "Insert of existing embedding ID: 8\n",
      "Insert of existing embedding ID: 9\n",
      "Insert of existing embedding ID: 10\n",
      "Insert of existing embedding ID: 11\n",
      "Insert of existing embedding ID: 12\n",
      "Insert of existing embedding ID: 13\n",
      "Insert of existing embedding ID: 14\n",
      "Insert of existing embedding ID: 15\n",
      "Insert of existing embedding ID: 16\n",
      "Insert of existing embedding ID: 17\n",
      "Insert of existing embedding ID: 18\n",
      "Insert of existing embedding ID: 19\n",
      "Insert of existing embedding ID: 20\n",
      "Insert of existing embedding ID: 21\n",
      "Insert of existing embedding ID: 22\n",
      "Insert of existing embedding ID: 23\n",
      "Insert of existing embedding ID: 24\n",
      "Insert of existing embedding ID: 25\n",
      "Insert of existing embedding ID: 26\n",
      "Insert of existing embedding ID: 27\n",
      "Insert of existing embedding ID: 28\n",
      "Insert of existing embedding ID: 29\n",
      "Insert of existing embedding ID: 30\n",
      "Insert of existing embedding ID: 31\n",
      "Insert of existing embedding ID: 32\n",
      "Insert of existing embedding ID: 33\n",
      "Insert of existing embedding ID: 34\n",
      "Insert of existing embedding ID: 35\n",
      "Insert of existing embedding ID: 36\n",
      "Insert of existing embedding ID: 37\n",
      "Insert of existing embedding ID: 38\n",
      "Insert of existing embedding ID: 39\n",
      "Insert of existing embedding ID: 40\n",
      "Insert of existing embedding ID: 41\n",
      "Insert of existing embedding ID: 42\n",
      "Insert of existing embedding ID: 43\n",
      "Insert of existing embedding ID: 44\n",
      "Insert of existing embedding ID: 45\n",
      "Insert of existing embedding ID: 46\n",
      "Insert of existing embedding ID: 47\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'info': [{'first_name': 'John',\n",
       "   'last_name': 'Dickinson',\n",
       "   'children': [{'first_name': 'William', 'last_name': 'Dickinson'},\n",
       "    {'first_name': 'Walter', 'last_name': 'Dickinson'},\n",
       "    {'first_name': 'Samuel', 'last_name': 'Dickinson'},\n",
       "    {'first_name': 'Elizabeth', 'last_name': 'Dickinson'},\n",
       "    {'first_name': 'Henry', 'last_name': 'Dickinson'},\n",
       "    {'first_name': 'Elizabeth', 'last_name': 'Dickinson'},\n",
       "    {'first_name': 'Rebecca', 'last_name': 'Dickinson'},\n",
       "    {'first_name': 'Rachel', 'last_name': 'Dickinson'}],\n",
       "   'cause_of_death': 'unknown'}]}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To reset the DB...\n",
    "collection = client.delete_collection(\"wiki_data_bs4\")\n",
    "collection = client.create_collection(\"wiki_data_bs4\", embedding_function=openai_ef)\n",
    "\n",
    "person_extraction_chain_wiki_split.invoke({\"url\": DICKINSON_URL, \"schema\": MORE_COMPLEX_INFO_SCHEMA})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
