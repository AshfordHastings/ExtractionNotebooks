{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implement an HTML Splitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ashfordhastings/PythonProjects/Practice Projects/prac-49-lc-book/.venv/lib/python3.9/site-packages/urllib3/__init__.py:34: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from typing import List, Dict\n",
    "import os\n",
    "import requests\n",
    "from bs4 import BeautifulSoup, Tag, ResultSet\n",
    "from markdownify import MarkdownConverter\n",
    "import chromadb\n",
    "import chromadb.utils.embedding_functions as embedding_functions\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from operator import itemgetter\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "from langchain_core.prompts.chat import ChatPromptTemplate\n",
    "from langchain.output_parsers.openai_functions import JsonKeyOutputFunctionsParser, JsonOutputFunctionsParser\n",
    "from langchain.schema.output_parser import StrOutputParser\n",
    "from langchain_openai.chat_models import ChatOpenAI\n",
    "import pandas as pd\n",
    "import mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaner methods\n",
    "from bs4 import ResultSet, Tag\n",
    "def remove_links_from_p(tag:Tag) -> None:\n",
    "    for link in tag.find_all('a'):\n",
    "        link.replace_with(link.text)\n",
    "\n",
    "def remove_citations_from_p(tag:Tag) -> None:\n",
    "    for citation in tag.find_all(class_=\"reference\"):\n",
    "        citation.decompose()\n",
    "\n",
    "def md(soup:str, **options):\n",
    "    return MarkdownConverter(**options).convert_soup(soup)\n",
    "\n",
    "def format_paragraph(element):\n",
    "    remove_links_from_p(element)\n",
    "    remove_citations_from_p(element)\n",
    "    return md(element)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_html_from_wiki_url(url:str) -> Tag:\n",
    "    res = requests.get(url, headers={})\n",
    "    if res.status_code == 200:\n",
    "        soup=BeautifulSoup(res.content,'html.parser')\n",
    "        return soup\n",
    "    else:\n",
    "        raise Exception(f\"Error loading page: {res.status_code}\")\n",
    "    \n",
    "def group_paragraphs_by_section(soup:Tag) -> Dict[str, List[Tag]]:\n",
    "    current_subtitle = \"Overview\"\n",
    "    grouped_content = {}\n",
    "    elements = soup.find_all(['h2', 'h3', 'p'])\n",
    "\n",
    "    for element in elements:\n",
    "        if element.name in ['h2', 'h3']:\n",
    "            current_subtitle = element.get_text(strip=True)\n",
    "            grouped_content[current_subtitle] = []\n",
    "        elif element.name == 'p':\n",
    "            grouped_content.setdefault(current_subtitle, []).append(element)\n",
    "\n",
    "    for subtitle, paragraphs in grouped_content.items():\n",
    "        grouped_content[subtitle] = [format_paragraph(p) for p in paragraphs]\n",
    "\n",
    "    return grouped_content\n",
    "\n",
    "def load_and_clean_from_wiki_url(url:str):\n",
    "    soup = load_html_from_wiki_url(url)\n",
    "    main = soup.find(id=\"mw-content-text\")\n",
    "    return group_paragraphs_by_section(main)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.documents import Document\n",
    "\n",
    "def split_wiki_pars(paragraph_content, splitter) -> List[Document]:\n",
    "    docs = []\n",
    "    for subtitle, paragraphs in paragraph_content.items():\n",
    "        if paragraphs is None:\n",
    "            continue\n",
    "        split_paragraphs = splitter.create_documents(\n",
    "            texts=paragraphs,\n",
    "            metadatas=[{\"subtitle\": subtitle, \"type\": \"paragraph\"} for _ in paragraphs]\n",
    "        )\n",
    "        docs.extend(split_paragraphs)\n",
    "    return docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_collection_from_wiki_url(wiki_url, collection, splitter, tags={}):\n",
    "    grouped_paragraphs = load_and_clean_from_wiki_url(wiki_url)\n",
    "    docs = split_wiki_pars(grouped_paragraphs, splitter)\n",
    "    collection.add(\n",
    "        documents=[doc.page_content for doc in docs],\n",
    "        ids=[str(i) for i in range(len(docs))],\n",
    "        metadatas=[doc.metadata | tags for doc in docs]\n",
    "    )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from chromadb import Collection\n",
    "\n",
    "def get_embeddings_for_question(x):\n",
    "    question = x['question']\n",
    "    collection:Collection = x['collection']\n",
    "    metadata_filters = x.get(\"metadata_filters\", {})\n",
    "    document_filters = x.get(\"document_filters\", {})\n",
    "    sim_docs = collection.query(query_texts=[question], n_results=3, where=metadata_filters, where_document=document_filters)['documents'][0]\n",
    "\n",
    "    #Combining the documents\n",
    "    full_context = \"\\n\".join([doc for doc in sim_docs])\n",
    "\n",
    "    return {\"input\": full_context}\n",
    "\n",
    "def combine_docs(x):\n",
    "    \"\"\"combines list of docs\"\"\"\n",
    "    docs = x['input']\n",
    "    full_context = \" \".join([doc.page_content for doc in docs])\n",
    "    return {\"input\": full_context}\n",
    "\n",
    "def invoke_model_with_question(x):\n",
    "    model = ChatOpenAI(temperature=0.0)\n",
    "    return model.invoke(x['input'].messages)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", template),\n",
    "    (\"human\", \"{input}\")\n",
    "])\n",
    "\n",
    "\"\"\"\n",
    "Person_QA_Wiki_Chain:\n",
    "inputs:\n",
    "    question: Single question for the LLM over a single context that is to be queried in the collection\n",
    "    collection: collection in which to query context for \n",
    "    metadata_filters (optional): Filter based on metadata \n",
    "    document_filters (optional): Filter based on documents (supports operator actions)\n",
    "\"\"\"\n",
    "person_qa_wiki_chain = (\n",
    "    {\n",
    "        \"input\": get_embeddings_for_question | prompt,\n",
    "    }\n",
    "    | RunnableLambda(invoke_model_with_question) \n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools\n",
    "\n",
    "def model(input_df:pd.DataFrame, **kwargs):\n",
    "    answer = []\n",
    "    for index, row in input_df.iterrows():\n",
    "        answer.append(person_qa_wiki_chain.invoke({\"question\": row[\"questions\"]} | kwargs))\n",
    "    return answer\n",
    "\n",
    "def model_factory(**kwargs):\n",
    "    def wrapped_model(input_df):\n",
    "        return model(input_df, **kwargs)\n",
    "    return wrapped_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metrics\n",
    "from mlflow.metrics.genai import relevance, faithfulness, EvaluationExample\n",
    "\n",
    "relevance_metric = relevance(\n",
    "    model=\"openai:/gpt-4\"\n",
    ")\n",
    "\n",
    "faithfulness_metric = faithfulness(\n",
    "    model=\"openai:/gpt-4\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create and Reset Initial Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "client = chromadb.Client()\n",
    "\n",
    "openai_ef = embedding_functions.OpenAIEmbeddingFunction(\n",
    "            api_key=os.environ[\"OPENAI_API_KEY\"],\n",
    "            model_name=\"text-embedding-ada-002\"\n",
    ")\n",
    "\n",
    "#client.delete_collection(\"wiki_data_bs4_mlflow\")\n",
    "wiki_collection = client.create_collection(\"wiki_data_bs4_mlflow\", embedding_function=openai_ef)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Data Inside of Collection\n",
    "DICKINSON_URL = \"https://en.wikipedia.org/wiki/John_Dickinson\"\n",
    "default_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)\n",
    "\n",
    "\n",
    "fill_collection_from_wiki_url(\n",
    "    wiki_url=DICKINSON_URL,\n",
    "    collection=wiki_collection,\n",
    "    splitter=default_splitter,\n",
    "    tags={\"subject\": \"John Dickinson\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Narrow Collection to Specific Context"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Validate Basic Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_df = pd.DataFrame(\n",
    "    {\n",
    "        \"questions\": [\n",
    "            \"Did John Dickinson support independence?\",\n",
    "            \"When was the John Dickinson born?\",\n",
    "            \"How many siblings did John Dickinson have?\"\n",
    "        ],\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_configs = {\n",
    "    \"collection\": wiki_collection,\n",
    "    \"metadata_filters\": {\"subject\": \"John Dickinson\"}\n",
    "}\n",
    "\n",
    "basic_model = model_factory(**model_configs)\n",
    "\n",
    "results = basic_model(eval_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Did John Dickinson support independence?\n",
      "Answer: Based on the given context, John Dickinson did not sign the Declaration of Independence.\n",
      "\n",
      "Question: When was the John Dickinson born?\n",
      "Answer: John Dickinson was a Founding Father of the United States, known as the \"Penman of the Revolution\" for his writings advocating for the rights of the American colonies. He served as president of Delaware from 1781 to 1783 and president of Pennsylvania from 1782 to 1785. However, he did not actually resign as president of Delaware when he was elected president of Pennsylvania, causing controversy and leading to his formal resignation in January 1783.\n",
      "\n",
      "Question: How many siblings did John Dickinson have?\n",
      "Answer: The Dickinson family had a total of 16 children.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for question, answer in zip(eval_df['questions'], results):\n",
    "    print(f\"Question: {question}\")\n",
    "    print(f\"Answer: {answer}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Perform Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.set_tracking_uri(\"http://localhost:5000\")\n",
    "mlflow.set_experiment(\"llm_wiki_rag\")\n",
    "os.environ[\"OPENAI_API_KEY\"]='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'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ashfordhastings/PythonProjects/Practice Projects/prac-49-lc-book/.venv/lib/python3.9/site-packages/mlflow/data/digest_utils.py:29: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  string_columns = trimmed_df.columns[(df.applymap(type) == str).all(0)]\n",
      "/Users/ashfordhastings/PythonProjects/Practice Projects/prac-49-lc-book/.venv/lib/python3.9/site-packages/mlflow/models/evaluation/base.py:414: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  data = data.applymap(_hash_array_like_element_as_bytes)\n",
      "2024/02/03 20:48:00 INFO mlflow.models.evaluation.base: Evaluating the model with the default evaluator.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/02/03 20:48:00 INFO mlflow.models.evaluation.default_evaluator: Computing model predictions.\n",
      "2024/02/03 20:48:08 INFO mlflow.models.evaluation.default_evaluator: Testing metrics on first row...\n",
      "2024/02/03 20:48:08 INFO mlflow.models.evaluation.default_evaluator: Evaluating metrics: flesch_kincaid_grade_level\n",
      "2024/02/03 20:48:08 INFO mlflow.models.evaluation.default_evaluator: Evaluating metrics: ari_grade_level\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'flesch_kincaid_grade_level/v1/mean': 9.966666666666667, 'flesch_kincaid_grade_level/v1/variance': 2.668888888888889, 'flesch_kincaid_grade_level/v1/p90': 11.58, 'ari_grade_level/v1/mean': 9.266666666666667, 'ari_grade_level/v1/variance': 14.675555555555556, 'ari_grade_level/v1/p90': 12.56}\n"
     ]
    }
   ],
   "source": [
    "model_configs = {\n",
    "    \"collection\": wiki_collection,\n",
    "    \"metadata_filters\": {\"subject\": \"John Dickinson\"}\n",
    "}\n",
    "\n",
    "results = mlflow.evaluate(\n",
    "    model_factory(**model_configs),\n",
    "    eval_df,\n",
    "    #model_type=\"question_answering\",\n",
    "    #extra_metrics=[faithfulness_metric, relevance_metric, mlflow.metrics.ari_grade_level(), mlflow.metrics.flesch_kincaid_grade_level()],\n",
    "    extra_metrics=[mlflow.metrics.flesch_kincaid_grade_level(), mlflow.metrics.ari_grade_level()],\n",
    "    evaluator_config={\n",
    "        \"col_mapping\": {\n",
    "            \"inputs\": \"questions\",\n",
    "            \"context\": \"source_documents\",\n",
    "        }\n",
    "    },\n",
    ")\n",
    "\n",
    "print(results.metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d7b0e50bc15418282057bb36b46d850",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>questions</th>\n",
       "      <th>outputs</th>\n",
       "      <th>flesch_kincaid_grade_level/v1/score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Did John Dickinson support independence?</td>\n",
       "      <td>Based on the given context, John Dickinson did...</td>\n",
       "      <td>9.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>When was the John Dickinson born?</td>\n",
       "      <td>John Dickinson was a Founding Father of the Un...</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>How many siblings did John Dickinson have?</td>\n",
       "      <td>The Dickinson family had a total of 16 children.</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    questions  \\\n",
       "0    Did John Dickinson support independence?   \n",
       "1           When was the John Dickinson born?   \n",
       "2  How many siblings did John Dickinson have?   \n",
       "\n",
       "                                             outputs  \\\n",
       "0  Based on the given context, John Dickinson did...   \n",
       "1  John Dickinson was a Founding Father of the Un...   \n",
       "2   The Dickinson family had a total of 16 children.   \n",
       "\n",
       "   flesch_kincaid_grade_level/v1/score  \n",
       "0                                  9.9  \n",
       "1                                 12.0  \n",
       "2                                  8.0  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.tables[\"eval_results_table\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='mlflow-artifacts:/480502914628502779', creation_time=1707015245531, experiment_id='480502914628502779', last_update_time=1707015245531, lifecycle_stage='active', name='llm_wiki_rag_test_dickinson', tags={'mlflow.note.content': 'This is a test experiment to see how well the LLM can '\n",
       "                        'answer questions about John Dickinson.',\n",
       " 'source': 'Wikipedia',\n",
       " 'subject': 'John Dickinson',\n",
       " 'type': 'RAG'}>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiment_description = (\n",
    "    \"This is a test experiment to see how well the LLM can answer questions about John Dickinson.\"\n",
    ")\n",
    "\n",
    "experiment_tags = {\n",
    "    \"subject\": \"John Dickinson\",\n",
    "    \"source\": \"Wikipedia\",\n",
    "    \"type\": \"RAG\",\n",
    "    \"mlflow.note.content\": experiment_description\n",
    "}\n",
    "\n",
    "llm_rag_experiment = mlflow.create_experiment(\n",
    "    name=\"llm_wiki_rag_test_dickinson\",\n",
    "    tags=experiment_tags\n",
    ")\n",
    "\n",
    "mlflow.set_experiment(\"llm_wiki_rag_test_dickinson\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ashfordhastings/PythonProjects/Practice Projects/prac-49-lc-book/.venv/lib/python3.9/site-packages/mlflow/data/digest_utils.py:29: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  string_columns = trimmed_df.columns[(df.applymap(type) == str).all(0)]\n",
      "/Users/ashfordhastings/PythonProjects/Practice Projects/prac-49-lc-book/.venv/lib/python3.9/site-packages/mlflow/models/evaluation/base.py:414: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  data = data.applymap(_hash_array_like_element_as_bytes)\n",
      "2024/02/03 21:20:25 INFO mlflow.models.evaluation.base: Evaluating the model with the default evaluator.\n",
      "2024/02/03 21:20:25 INFO mlflow.models.evaluation.default_evaluator: Computing model predictions.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/02/03 21:20:33 INFO mlflow.models.evaluation.default_evaluator: Testing metrics on first row...\n",
      "2024/02/03 21:20:33 INFO mlflow.models.evaluation.default_evaluator: Evaluating metrics: flesch_kincaid_grade_level\n",
      "2024/02/03 21:20:33 INFO mlflow.models.evaluation.default_evaluator: Evaluating metrics: ari_grade_level\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "\n",
    "model_configs = {\n",
    "    \"collection\": wiki_collection,\n",
    "    \"metadata_filters\": {\"subject\": \"John Dickinson\"}\n",
    "}\n",
    "\n",
    "with mlflow.start_run(run_name=\"test_1\") as run:\n",
    "    # logged_model_info = mlflow.openai.log_model(\n",
    "    #     model=\"text-embedding-ada-002\",\n",
    "    #     task=openai.ChatCompletion,\n",
    "    #     artifact_path=\"model\",\n",
    "    #     messages=[\n",
    "    #         {\"role\": \"system\", \"content\": prompt},\n",
    "    #         {\"role\": \"user\", \"content\": \"{question}\"},\n",
    "    #     ],\n",
    "    # )\n",
    "    mlflow.set_tags({\n",
    "        \"prompt_template\": template\n",
    "    })\n",
    "    results = mlflow.evaluate(\n",
    "        model_factory(**model_configs),\n",
    "        eval_df,\n",
    "        #model_type=\"question_answering\",\n",
    "        #extra_metrics=[faithfulness_metric, relevance_metric, mlflow.metrics.ari_grade_level(), mlflow.metrics.flesch_kincaid_grade_level()],\n",
    "        extra_metrics=[mlflow.metrics.flesch_kincaid_grade_level(), mlflow.metrics.ari_grade_level()],\n",
    "        evaluator_config={\n",
    "            \"col_mapping\": {\n",
    "                \"inputs\": \"questions\",\n",
    "                \"context\": \"source_documents\",\n",
    "            }\n",
    "        },\n",
    "\n",
    "\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e623799e2d342efb37811b66483d630",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>questions</th>\n",
       "      <th>outputs</th>\n",
       "      <th>flesch_kincaid_grade_level/v1/score</th>\n",
       "      <th>ari_grade_level/v1/score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Did John Dickinson support independence?</td>\n",
       "      <td>Based on the given context, John Dickinson did...</td>\n",
       "      <td>9.9</td>\n",
       "      <td>10.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>When was the John Dickinson born?</td>\n",
       "      <td>John Dickinson served as the president of whic...</td>\n",
       "      <td>4.8</td>\n",
       "      <td>7.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>How many siblings did John Dickinson have?</td>\n",
       "      <td>The Dickinson family had a total of 16 children.</td>\n",
       "      <td>8.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    questions  \\\n",
       "0    Did John Dickinson support independence?   \n",
       "1           When was the John Dickinson born?   \n",
       "2  How many siblings did John Dickinson have?   \n",
       "\n",
       "                                             outputs  \\\n",
       "0  Based on the given context, John Dickinson did...   \n",
       "1  John Dickinson served as the president of whic...   \n",
       "2   The Dickinson family had a total of 16 children.   \n",
       "\n",
       "   flesch_kincaid_grade_level/v1/score  ari_grade_level/v1/score  \n",
       "0                                  9.9                      10.8  \n",
       "1                                  4.8                       7.1  \n",
       "2                                  8.0                       4.0  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_table = results.tables[\"eval_results_table\"]\n",
    "eval_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
